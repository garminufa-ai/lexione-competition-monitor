"""
FastAPI-—Å–µ—Ä–≤–µ—Ä –¥–ª—è LexiOne Competition Monitor.
–≠–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, —Ç–µ–∫—Å—Ç–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤.
"""

import json
from pathlib import Path
from datetime import datetime
from typing import Optional, List
from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

from app.config import OUTPUTS_DIR, HISTORY_DIR, SCREENSHOTS_DIR
from app.openai_service import analyze_image, analyze_text
from app.parsing_service import parse_competitors_list, parse_website, get_parsed_text


app = FastAPI(
    title="LexiOne Competition Monitor API",
    description="API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–∞–π—Ç–æ–≤ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤",
    version="1.0.0"
)

# CORS –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ UI
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# –ú–æ–¥–µ–ª–∏ –∑–∞–ø—Ä–æ—Å–æ–≤/–æ—Ç–≤–µ—Ç–æ–≤
class CompetitorItem(BaseModel):
    name: str = ""
    url: str


class ParseRequest(BaseModel):
    competitors: List[CompetitorItem]


class TextAnalysisRequest(BaseModel):
    text: str
    competitor_name: Optional[str] = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π"


class AnalysisResponse(BaseModel):
    success: bool
    data: dict
    error: Optional[str] = None


# === –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã ===

@app.get("/")
async def root():
    """–ö–æ—Ä–Ω–µ–≤–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç ‚Äî –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± API."""
    return {
        "name": "LexiOne Competition Monitor API",
        "version": "1.0.0",
        "endpoints": {
            "/analyze-image": "POST - –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/—Å–∫—Ä–∏–Ω—à–æ—Ç–∞",
            "/analyze-text": "POST - –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞",
            "/parse": "POST - –ü–∞—Ä—Å–∏–Ω–≥ —Å–ø–∏—Å–∫–∞ URL –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤",
            "/parse-single": "POST - –ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ URL"
        }
    }


@app.post("/analyze-image", response_model=AnalysisResponse)
async def endpoint_analyze_image(
    file: UploadFile = File(...),
    competitor_name: str = Form(default="–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π")
):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Å–∫—Ä–∏–Ω—à–æ—Ç —Å–∞–π—Ç–∞).
    
    - **file**: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (PNG, JPG, WEBP)
    - **competitor_name**: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
        allowed_types = ["image/png", "image/jpeg", "image/jpg", "image/webp"]
        if file.content_type not in allowed_types:
            raise HTTPException(
                status_code=400,
                detail=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {file.content_type}"
            )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        ext = Path(file.filename).suffix or ".png"
        temp_path = SCREENSHOTS_DIR / f"upload_{timestamp}{ext}"
        
        content = await file.read()
        with open(temp_path, "wb") as f:
            f.write(content)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
        result = analyze_image(temp_path, competitor_name)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        _save_to_history("image_analysis", competitor_name, result)
        
        return AnalysisResponse(success=True, data=result)
        
    except Exception as e:
        return AnalysisResponse(success=False, data={}, error=str(e))


@app.post("/analyze-text", response_model=AnalysisResponse)
async def endpoint_analyze_text(request: TextAnalysisRequest):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å–∞–π—Ç–∞.
    
    - **text**: HTML –∏–ª–∏ —Ç–µ–∫—Å—Ç —Å–∞–π—Ç–∞
    - **competitor_name**: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
    """
    try:
        if not request.text.strip():
            raise HTTPException(status_code=400, detail="–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        
        result = analyze_text(request.text, request.competitor_name)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        _save_to_history("text_analysis", request.competitor_name, result)
        
        return AnalysisResponse(success=True, data=result)
        
    except Exception as e:
        return AnalysisResponse(success=False, data={}, error=str(e))


@app.post("/parse")
async def endpoint_parse(request: ParseRequest):
    """
    –ü–∞—Ä—Å–∏—Ç —Å–ø–∏—Å–æ–∫ URL –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏—Ö.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ (GPT-4o-mini –≤–º–µ—Å—Ç–æ GPT-4o vision).
    
    - **competitors**: –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–ª—è–º–∏ name –∏ url
    """
    try:
        if not request.competitors:
            raise HTTPException(status_code=400, detail="–°–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –ø—É—Å—Ç")
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
        competitors_list = [
            {"name": c.name, "url": c.url} 
            for c in request.competitors
        ]
        
        total = len(competitors_list)
        print(f"üìã –ù–∞—á–∏–Ω–∞—é –ø–∞—Ä—Å–∏–Ω–≥ {total} —Å–∞–π—Ç–æ–≤...")
        
        # –ü–∞—Ä—Å–∏–º —Å–∞–π—Ç—ã –ë–ï–ó —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        parsed_results = parse_competitors_list(competitors_list, save_screenshots=False)
        
        print(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –¥–∞–Ω–Ω—ã–µ...")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–≥–æ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
        analysis_results = []
        
        for idx, parsed in enumerate(parsed_results, 1):
            print(f"üîç –ê–Ω–∞–ª–∏–∑ {idx}/{total}: {parsed['name']}...")
            
            competitor_result = {
                "name": parsed["name"],
                "url": parsed["url"],
                "parsing_success": parsed["success"],
                "parsing_error": parsed.get("error"),
                "analysis": None
            }
            
            if parsed["success"]:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¢–ï–ö–°–¢–û–í–´–ô –∞–Ω–∞–ª–∏–∑ (–±—ã—Å—Ç—Ä–µ–µ –≤ 3-5 —Ä–∞–∑)
                try:
                    text = get_parsed_text(parsed)
                    competitor_result["analysis"] = analyze_text(text, parsed["name"])
                    competitor_result["analysis_type"] = "text"
                except Exception as e:
                    competitor_result["analysis_error"] = str(e)
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {parsed['name']}: {e}")
            else:
                print(f"‚ö†Ô∏è –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è: {parsed.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
            
            analysis_results.append(competitor_result)
        
        print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω!")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç
        report = {
            "timestamp": datetime.now().isoformat(),
            "total_competitors": len(analysis_results),
            "successful": sum(1 for r in analysis_results if r["parsing_success"]),
            "results": analysis_results
        }
        
        _save_report(report)
        
        return {
            "success": True,
            "report": report
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "report": None
        }


@app.post("/parse-single")
async def endpoint_parse_single(url: str = Form(...), name: str = Form(default="")):
    """
    –ü–∞—Ä—Å–∏—Ç –æ–¥–∏–Ω URL –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç.
    
    - **url**: URL —Å–∞–π—Ç–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–∞
    - **name**: –ù–∞–∑–≤–∞–Ω–∏–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """
    try:
        # –ü–∞—Ä—Å–∏–º —Å–∞–π—Ç
        parsed = parse_website(url, name if name else None, save_screenshot=True)
        
        result = {
            "name": parsed["name"],
            "url": parsed["url"],
            "parsing_success": parsed["success"],
            "parsing_error": parsed.get("error"),
            "analysis": None
        }
        
        if parsed["success"]:
            screenshot_path = parsed["data"].get("screenshot_path")
            
            if screenshot_path and Path(screenshot_path).exists():
                try:
                    result["analysis"] = analyze_image(screenshot_path, parsed["name"])
                    result["analysis_type"] = "image"
                except:
                    text = get_parsed_text(parsed)
                    result["analysis"] = analyze_text(text, parsed["name"])
                    result["analysis_type"] = "text"
            else:
                text = get_parsed_text(parsed)
                result["analysis"] = analyze_text(text, parsed["name"])
                result["analysis_type"] = "text"
        
        _save_to_history("single_parse", result["name"], result)
        
        return {"success": True, "result": result}
        
    except Exception as e:
        return {"success": False, "error": str(e), "result": None}


@app.get("/history")
async def get_history(limit: int = 10):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –∞–Ω–∞–ª–∏–∑–æ–≤."""
    history_files = sorted(
        HISTORY_DIR.glob("*.json"),
        key=lambda x: x.stat().st_mtime,
        reverse=True
    )[:limit]
    
    history = []
    for f in history_files:
        try:
            with open(f, "r", encoding="utf-8") as file:
                history.append(json.load(file))
        except:
            pass
    
    return {"history": history}


# === –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ===

def _save_to_history(analysis_type: str, competitor_name: str, result: dict):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{analysis_type}_{timestamp}.json"
    
    data = {
        "type": analysis_type,
        "competitor": competitor_name,
        "timestamp": datetime.now().isoformat(),
        "result": result
    }
    
    with open(HISTORY_DIR / filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def _save_report(report: dict):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç."""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"report_{timestamp}.json"
    
    with open(OUTPUTS_DIR / filename, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)


# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
if __name__ == "__main__":
    import uvicorn
    from app.config import API_HOST, API_PORT
    uvicorn.run(app, host=API_HOST, port=API_PORT)
